{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5101ead2-e06b-462f-bb35-762ea042785e",
   "metadata": {},
   "source": [
    "# AIMLCZG567_Assignment_1_Group_18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddc898-4ad1-4bca-a3b3-6eb2478b3b98",
   "metadata": {},
   "source": [
    "                          \n",
    "| Name            | BITS_ID     | Contribution |\n",
    "|-----------------|-------------|--------------|\n",
    "| Rahul           | 2024ad05284 | 100%         |\n",
    "| Ankita Yadav    | 2024AC05681 | 100%         |\n",
    "|Rasampreet Singh |             | 100%         |\n",
    "|Srinidhi S       | 2024AC05595 | 100%         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cff4a-5b85-4ef4-8376-8d7a7c47cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# ML Imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa87f7c-25a8-48dc-a2fa-34f6260c5616",
   "metadata": {},
   "source": [
    "## LOAD CISA KEV DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c433b-0ad9-41ef-9b2e-1b43ab93dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cisa_kev():\n",
    "    print(\"Loading CISA KEV data...\")\n",
    "    url = \"https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json\"\n",
    "    data = requests.get(url).json()\n",
    "    kev_df = pd.DataFrame(data['vulnerabilities'])\n",
    "    kev_ids = set(item['cveID'] for item in data['vulnerabilities'])\n",
    "    print(f\"Loaded {len(kev_ids)} exploited CVEs from CISA. Sample....\")\n",
    "    print(kev_df.head())\n",
    "    \n",
    "    return kev_ids, kev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e615489-a76b-49e8-a638-7a053a069db1",
   "metadata": {},
   "source": [
    "## Fetch CVEs from NVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8c1b42-044c-4382-a3fd-1d238f543b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cves(start_date=\"2025-01-01\", end_date=\"2025-04-30\", results_per_page=2000, apikey= None)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch CVEs from NVD API within a given date range.\n",
    "    \n",
    "    Args:\n",
    "        start_date (str): Start date in YYYY-MM-DD format.\n",
    "        end_date (str): End date in YYYY-MM-DD format.\n",
    "        Note : The maximum allowable range when using any date range parameters is 120 consecutive days.\n",
    "        results_per_page (int): Number of results per page (max 2000).\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "        list: A Data frame of CVE items.\n",
    "    \"\"\"\n",
    "    print(\"\\n Fetching CVEs for given date range...\")\n",
    "    base_url = f\"https://services.nvd.nist.gov/rest/json/cves/2.0/?pubStartDate={start_date}T00:00:00.000&pubEndDate={end_date}T00:00:00.000\"\n",
    "    headers = {\"apiKey\" : apikey}\n",
    "\n",
    "    all_cves = []\n",
    "    start_index = 0\n",
    "\n",
    "    while True:\n",
    "        url = f\"{base_url}&startIndex={start_index}&resultsPerPage={results_per_page}\"\n",
    "        response = requests.get(url, headers = headers )\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Error fetching data: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        data = response.json()\n",
    "        cves = data.get(\"vulnerabilities\", [])\n",
    "        all_cves.extend(cves)\n",
    "        \n",
    "        # Check if there are more pages\n",
    "        total_results = data.get(\"totalResults\", 0)\n",
    "        start_index += results_per_page\n",
    "        \n",
    "        if start_index >= total_results:\n",
    "            break\n",
    "\n",
    "    print(f\"Loaded {len(all_cves)} CVEs from NVD. Sample....\")\n",
    "    fetched_cve_df = pd.DataFrame(all_cves)\n",
    "    print(fetched_cve_df.head())\n",
    "    return fetched_cve_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317852b8-7843-4e23-b69f-1ff1f7c16afa",
   "metadata": {},
   "source": [
    "## Flatten CVEs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2618f1ab-6574-45ce-b6b3-d38b54356c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_cve(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flatten the NVD 'vulnerabilities' structure from the DataFrame returned by fetch_cves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_raw : pd.DataFrame\n",
    "        DataFrame returned by fetch_cves. Expected to have a column 'cve' with dicts.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Flattened DataFrame with selected NVD CVE fields.\n",
    "    \"\"\"\n",
    "    if \"cve\" not in df_raw.columns:\n",
    "        raise ValueError(\"Input df_raw must have a 'cve' column containing NVD CVE dicts.\")\n",
    "\n",
    "    # Normalize the nested 'cve' objects\n",
    "    df_cve = pd.json_normalize(df_raw[\"cve\"], sep=\".\")\n",
    "\n",
    "    # --- Ensure expected columns exist ---\n",
    "    for col, default in [\n",
    "        (\"descriptions\", []),\n",
    "        (\"metrics\", {}),\n",
    "        (\"weaknesses\", []),\n",
    "        (\"configurations\", []),\n",
    "        (\"references\", []),\n",
    "    ]:\n",
    "        if col not in df_cve.columns:\n",
    "            df_cve[col] = [default] * len(df_cve)\n",
    "\n",
    "    # --- Utilities ---\n",
    "    def _pick_english_description(descriptions):\n",
    "        if isinstance(descriptions, list):\n",
    "            for d in descriptions:\n",
    "                if d.get(\"lang\", \"\").lower() == \"en\":\n",
    "                    return d.get(\"value\")\n",
    "            return descriptions[0].get(\"value\") if descriptions else None\n",
    "        return None\n",
    "\n",
    "    def _extract_cvss(metrics):\n",
    "        \"\"\"\n",
    "        Prefer v3.1, then v3.0, then v2. Returns dict with basic fields only.\n",
    "        \"\"\"\n",
    "        out = {\n",
    "            \"cvss_version\": None,\n",
    "            \"cvss_score\": None,\n",
    "            \"cvss_severity\": None,\n",
    "            \"cvss_vector\": None,\n",
    "            \"exploitability_score\": None,\n",
    "            \"impact_score\": None,\n",
    "        }\n",
    "        if not isinstance(metrics, dict):\n",
    "            return out\n",
    "\n",
    "        def pick(metric_list, version_label):\n",
    "            if isinstance(metric_list, list) and metric_list:\n",
    "                m = metric_list[0]\n",
    "                data = m.get(\"cvssData\", {})\n",
    "                return {\n",
    "                    \"cvss_version\": version_label,\n",
    "                    \"cvss_score\": data.get(\"baseScore\"),\n",
    "                    \"cvss_severity\": data.get(\"baseSeverity\"),\n",
    "                    \"cvss_vector\": data.get(\"vectorString\"),\n",
    "                    \"exploitability_score\": m.get(\"exploitabilityScore\"),\n",
    "                    \"impact_score\": m.get(\"impactScore\"),\n",
    "                }\n",
    "            return None\n",
    "\n",
    "        for key, label in [(\"cvssMetricV31\", \"3.1\"), (\"cvssMetricV30\", \"3.0\"), (\"cvssMetricV2\", \"2.0\")]:\n",
    "            candidate = pick(metrics.get(key), label)\n",
    "            if candidate:\n",
    "                return candidate\n",
    "        return out\n",
    "\n",
    "    def _extract_cwes(weaknesses):\n",
    "        \"\"\"\n",
    "        Collect CWE identifiers (e.g., 'CWE-79') from weaknesses[].description[].value\n",
    "        \"\"\"\n",
    "        cwes = []\n",
    "        if isinstance(weaknesses, list):\n",
    "            for w in weaknesses:\n",
    "                for d in w.get(\"description\", []):\n",
    "                    val = d.get(\"value\")\n",
    "                    if val and \"CWE-\" in val:\n",
    "                        cwes.append(val)\n",
    "        cwes = sorted(set(cwes))\n",
    "        return \";\".join(cwes) if cwes else None\n",
    "\n",
    "    def _parse_cpe23_uri(cpe_uri):\n",
    "        # cpe:2.3:<part>:<vendor>:<product>:<version>:<update>:<edition>:<language>:...\n",
    "        try:\n",
    "            parts = cpe_uri.split(\":\")\n",
    "            return {\n",
    "                \"cpe_part\": parts[2] if len(parts) > 2 else None,     # 'a','o','h'\n",
    "                \"cpe_vendor\": parts[3] if len(parts) > 3 else None,\n",
    "                \"cpe_product\": parts[4] if len(parts) > 4 else None,\n",
    "                \"cpe_version\": parts[5] if len(parts) > 5 else None,\n",
    "            }\n",
    "        except Exception:\n",
    "            return {\"cpe_part\": None, \"cpe_vendor\": None, \"cpe_product\": None, \"cpe_version\": None}\n",
    "\n",
    "    def _extract_affected_software(configurations):\n",
    "        \"\"\"\n",
    "        Aggregate vendors/products/versions/part categories from configurations[].cpeMatch[].\n",
    "        \"\"\"\n",
    "        vendors, products, versions, parts = set(), set(), set(), set()\n",
    "        if not isinstance(configurations, list):\n",
    "            return {\n",
    "                \"affected_vendors\": None,\n",
    "                \"affected_products\": None,\n",
    "                \"affected_versions\": None,\n",
    "                \"affected_part_categories\": None,\n",
    "            }\n",
    "        for node in configurations:\n",
    "            for match in node.get(\"cpeMatch\", []):\n",
    "                cpe = match.get(\"criteria\") or match.get(\"cpe23Uri\")\n",
    "                if not cpe:\n",
    "                    continue\n",
    "                parsed = _parse_cpe23_uri(cpe)\n",
    "                v, p, ver, part = parsed[\"cpe_vendor\"], parsed[\"cpe_product\"], parsed[\"cpe_version\"], parsed[\"cpe_part\"]\n",
    "                if v: vendors.add(v)\n",
    "                if p: products.add(p)\n",
    "                if ver and ver not in {\"*\", \"-\"}:  # filter placeholders\n",
    "                    versions.add(ver)\n",
    "                if part:\n",
    "                    parts.add({\"a\": \"application\", \"o\": \"operating_system\", \"h\": \"hardware\"}.get(part, part))\n",
    "        return {\n",
    "            \"affected_vendors\": \";\".join(sorted(vendors)) if vendors else None,\n",
    "            \"affected_products\": \";\".join(sorted(products)) if products else None,\n",
    "            \"affected_versions\": \";\".join(sorted(versions)) if versions else None,\n",
    "            \"affected_part_categories\": \";\".join(sorted(parts)) if parts else None,\n",
    "        }\n",
    "\n",
    "    def _extract_reference_features(refs):\n",
    "        \"\"\"\n",
    "        Basic counts of references and tags (no binarization or leakage handling here).\n",
    "        \"\"\"\n",
    "        n_refs = 0\n",
    "        n_exploit = 0\n",
    "        n_patch = 0\n",
    "        n_vendor_adv = 0\n",
    "        has_exploit_tag = 0\n",
    "        if isinstance(refs, list):\n",
    "            for r in refs:\n",
    "                n_refs += 1\n",
    "                tags = [t.lower() for t in (r.get(\"tags\") or [])]\n",
    "                if \"exploit\" in tags:\n",
    "                    n_exploit += 1\n",
    "                    has_exploit_tag = 1\n",
    "                if \"patch\" in tags:\n",
    "                    n_patch += 1\n",
    "                if \"vendor advisory\" in tags:\n",
    "                    n_vendor_adv += 1\n",
    "        return {\n",
    "            \"references_count\": n_refs,\n",
    "            \"references_exploit_count\": n_exploit,\n",
    "            \"references_patch_count\": n_patch,\n",
    "            \"references_vendor_advisory_count\": n_vendor_adv,\n",
    "            \"has_exploit_tag\": has_exploit_tag,\n",
    "        }\n",
    "\n",
    "    # --- Core fields ---\n",
    "    df_cve[\"cve_id\"] = df_cve.get(\"id\")\n",
    "    df_cve[\"published\"] = pd.to_datetime(df_cve.get(\"published\"), errors=\"coerce\")\n",
    "    df_cve[\"last_modified\"] = pd.to_datetime(df_cve.get(\"lastModified\"), errors=\"coerce\")\n",
    "    df_cve[\"vuln_status\"] = df_cve.get(\"vulnStatus\")\n",
    "\n",
    "    # Descriptions\n",
    "    df_cve[\"description\"] = df_cve[\"descriptions\"].apply(_pick_english_description)\n",
    "\n",
    "    # CVSS\n",
    "    cvss_series = df_cve[\"metrics\"].apply(_extract_cvss)\n",
    "    cvss_df = pd.DataFrame(cvss_series.tolist())\n",
    "    df_cve = pd.concat([df_cve, cvss_df], axis=1)\n",
    "\n",
    "    # CWE(s)\n",
    "    df_cve[\"cwes\"] = df_cve[\"weaknesses\"].apply(_extract_cwes)\n",
    "\n",
    "    # Affected software (CPE)\n",
    "    affected_series = df_cve[\"configurations\"].apply(_extract_affected_software)\n",
    "    affected_df = pd.DataFrame(affected_series.tolist())\n",
    "    df_cve = pd.concat([df_cve, affected_df], axis=1)\n",
    "\n",
    "    # References\n",
    "    refs_series = df_cve[\"references\"].apply(_extract_reference_features)\n",
    "    refs_df = pd.DataFrame(refs_series.tolist())\n",
    "    df_cve = pd.concat([df_cve, refs_df], axis=1)\n",
    "\n",
    "    # Final columns \n",
    "    cols = [\n",
    "        \"cve_id\",\n",
    "        \"published\", \"last_modified\", \"vuln_status\",\n",
    "        \"cvss_version\", \"cvss_score\", \"cvss_severity\", \"cvss_vector\",\n",
    "        \"exploitability_score\", \"impact_score\",\n",
    "        \"cwes\",\n",
    "        \"affected_part_categories\", \"affected_vendors\", \"affected_products\", \"affected_versions\",\n",
    "        \"references_count\", \"references_exploit_count\", \"references_patch_count\",\n",
    "        \"references_vendor_advisory_count\", \"has_exploit_tag\",\n",
    "        \"description\",\n",
    "    ]\n",
    "    existing_cols = [c for c in cols if c in df_cve.columns]\n",
    "    flatten_cve_df = df_cve[existing_cols].copy()\n",
    "    print(\"\\n Flatten CVEs...\")\n",
    "    print(flatten_cve_df.head())\n",
    "    return flatten_cve_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991d5ca8-152c-4f38-b0c2-6b3032e36a20",
   "metadata": {},
   "source": [
    "## LABEL CVEs data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a6160a4-10b9-4e02-a380-85da4000f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_cve_data(df, kev_ids):\n",
    "    \"\"\"\n",
    "    Label a CVE 1 if it is present in KEV , 0 otherwsie\n",
    "    \"\"\"\n",
    "    print(\"Labeling exploited vulnerabilities...\")\n",
    "    df['exploited'] = df['cve_id'].apply(lambda x: 1 if x in kev_ids else 0)\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    print(df['exploited'].value_counts())\n",
    " \n",
    "  # Pie chart\n",
    "    counts = df['exploited'].value_counts()\n",
    "    labels = ['Not Exploited', 'Exploited']\n",
    "    sizes = [counts.get(0, 0), counts.get(1, 0)]\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#ff9999'])\n",
    "    plt.title('CVE Exploitation Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f0dd0",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfe5b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cve_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean raw labelled CVE dataframe from NVD+KEV.\n",
    "\n",
    "    Expected columns:\n",
    "    ['cve_id', 'published', 'last_modified', 'vuln_status',\n",
    "     'cvss_score', 'cvss_severity', 'cvss_vector',\n",
    "     'exploitability_score', 'impact_score',\n",
    "     'references_count', 'references_exploit_count',\n",
    "     'references_patch_count', 'references_vendor_advisory_count',\n",
    "     'has_exploit_tag', 'description', 'exploited']\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- Basic sanity cleanup ---\n",
    "\n",
    "    # (A) Drop rows without CVE id or description \n",
    "    df = df.dropna(subset=['cve_id', 'description'])\n",
    "\n",
    "    # (B) Parse datetime columns\n",
    "    df['published'] = pd.to_datetime(df['published'], errors='coerce')\n",
    "    df['last_modified'] = pd.to_datetime(df['last_modified'], errors='coerce')\n",
    "\n",
    "    # (C) Drop rows where we completely failed to parse published date\n",
    "    df = df.dropna(subset=['published'])\n",
    "\n",
    "    # (D) Remove clearly unhelpful CVEs (e.g., Rejected)\n",
    "    # Keep only actually analyzed/valid vulns\n",
    "    valid_statuses = ['Analyzed', 'Modified', 'Undergoing Analysis']\n",
    "    df = df[df['vuln_status'].isin(valid_statuses)]\n",
    "\n",
    "    # (E) Deduplicate by CVE id: keep the latest version\n",
    "    df = df.sort_values('last_modified').drop_duplicates(subset='cve_id', keep='last')\n",
    "\n",
    "    # (F) Reset index for cleanliness\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a9052c",
   "metadata": {},
   "source": [
    "#### **Reasoning for the different Cleaning methods used:**\n",
    "\n",
    "##### **(A) dropna(subset=['cve_id', 'description'])**\n",
    "Removes rows where:  \n",
    "1. cve_id is missing, or  \n",
    "2. description is missing.\n",
    "\n",
    "Missing cve_id → Can't be linked to KEV, can’t be used in analysis, can't dedupe, and is basically a broken row. Keeping it adds noise but no value.\n",
    "\n",
    "Missing description → The description text is one of the main feature sources (TF-IDF, keywords like “RCE”, “authentication bypass”, etc.).  \n",
    "A row with no description gives no text features and means that the NVD entry is incomplete.\n",
    "\n",
    "\n",
    "\n",
    "##### **(B) Parsing datetime columns with pd.to_datetime(...)**\n",
    "It converts strings like \"2025-01-08 23:15:09.763\" into real datetime objects.\n",
    "\n",
    "The analysis cares about temporal characteristics and proper validations. We need features like  \n",
    "1. age in days,  \n",
    "2. published year/month, \n",
    "3. “days between publication and last modification”.\n",
    "\n",
    "The temporal validations require published and last_modified to be actual datetimes, not raw strings. Without parsing these as datetimes,it is difficult to analyse time-based split or temporal feature.\n",
    "\n",
    "\n",
    "##### **(C) dropna(subset=['published'])**\n",
    " Removes rows where 'published' is missing or failed to parse.  \n",
    "Temporal validation is key to avoiding data leakage.\n",
    "A CVE cannot be correctly placed on a timeline if we have no information on when it was published.\n",
    "\n",
    "So rows with no published date \n",
    "1. cannot be used in a time-aware ML setup,\n",
    "2. would force into hacks (e.g., treating them as 0 or current date — both bad).\n",
    "\n",
    "\n",
    "##### **(D) df = df[df['vuln_status'].isin(valid_statuses)]**\n",
    "\n",
    "**\"Rejected\", \"Reserved\", \"Awaiting Analysis\"** must be removed because these records are NOT real vulnerabilities, and keeping them destroys model validity.\n",
    "\n",
    "1. Rejected CVEs\n",
    "* They contain no CVSS score\n",
    "* They can NEVER be exploited → label is always 0\n",
    "* They create trivial negatives, inflating accuracy and breaking the model\n",
    "Therefore they must be removed.\n",
    "\n",
    "2. Reserved CVEs\n",
    "* Description is generic\n",
    "* No metadata\n",
    "* Not released yet\n",
    "* Impossible to model\n",
    "These should also be removed.\n",
    "\n",
    "3. Awaiting Analysis - NVD hasn’t filled the fields yet.\n",
    "* Missing CVSS\n",
    "* Missing CWE\n",
    "* Missing products\n",
    "* Often “skeleton” data  \n",
    "These create noise.\n",
    "\n",
    "\n",
    "##### **(E) drop_duplicates(subset='cve_id', keep='last') after sorting by last_modified**\n",
    "NVD entries are mutable:\n",
    "1. New CVSS scores may be added.\n",
    "2. Additional references may appear.\n",
    "3. Severity or CWE may be updated.\n",
    "\n",
    "If we keep multiple rows per CVE:\n",
    "1. It artificially overweights certain CVEs,\n",
    "2. Inconsistent labels if something went wrong during labeling,\n",
    "3. Evaluation could go wwrong (same CVE in both train and test).\n",
    "\n",
    "So **deduping** by cve_id is about:\n",
    "* data integrity (1 row per entity),\n",
    "* avoiding leakage (no duplication across time splits),\n",
    "* cleaner analysis.\n",
    "\n",
    "##### **(F) reset_index(drop=True)**\n",
    "Resetting makes:\n",
    "* debugging easier,\n",
    "* logs and .head() outputs cleaner,\n",
    "* alignment with X / y consistency more obvious.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc0351a",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Engineer features for CVE exploitation prediction.\n",
    "\n",
    "    Returns:\n",
    "        X        : sparse matrix of features (text + numeric)\n",
    "        y        : numpy array of labels (0/1)\n",
    "        tfidf    : fitted TfidfVectorizer on description\n",
    "        num_cols : list of numeric feature column names\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ---------- Target ----------\n",
    "    y = df['exploited'].astype(int).values\n",
    "\n",
    "    # ---------- Temporal features ----------\n",
    "    # Age of the record in days between publish and last_modified\n",
    "    df['last_modified'] = pd.to_datetime(df['last_modified'], errors='coerce')\n",
    "    df['published'] = pd.to_datetime(df['published'], errors='coerce')\n",
    "\n",
    "    df['age_days'] = (df['last_modified'] - df['published']).dt.days\n",
    "    df['age_days'] = df['age_days'].fillna(0).clip(lower=0)\n",
    "\n",
    "    # Year and month of publication (can help with trend shifts)\n",
    "    df['published_year'] = df['published'].dt.year\n",
    "    df['published_month'] = df['published'].dt.month\n",
    "\n",
    "    # ---------- CVSS-related numeric features ----------\n",
    "    num_cols_raw = [\n",
    "        'cvss_score',\n",
    "        'exploitability_score',\n",
    "        'impact_score',\n",
    "        'references_count',\n",
    "        'references_exploit_count',\n",
    "        'references_patch_count',\n",
    "        'references_vendor_advisory_count',\n",
    "        'has_exploit_tag',\n",
    "    ]\n",
    "\n",
    "    # Make sure these are numeric\n",
    "    for col in num_cols_raw:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else:\n",
    "            # If column missing, create it as 0\n",
    "            df[col] = 0.0\n",
    "\n",
    "    df[num_cols_raw] = df[num_cols_raw].fillna(0)\n",
    "\n",
    "    # Encode cvss_severity into an ordinal numeric feature\n",
    "    severity_map = {\n",
    "        'NONE': 0,\n",
    "        'LOW': 1,\n",
    "        'MEDIUM': 2,\n",
    "        'HIGH': 3,\n",
    "        'CRITICAL': 4\n",
    "    }\n",
    "    df['cvss_severity_num'] = df['cvss_severity'].map(severity_map).fillna(0).astype(int)\n",
    "\n",
    "    # Simple parsing of CVSS vector (e.g., \"AV:N/AC:L/...\")\n",
    "    # Network vs Local etc.\n",
    "    vec = df['cvss_vector'].fillna('')\n",
    "\n",
    "    df['av_network'] = vec.str.contains('AV:N', na=False).astype(int)\n",
    "    df['av_adjacent'] = vec.str.contains('AV:A', na=False).astype(int)\n",
    "    df['av_local'] = vec.str.contains('AV:L', na=False).astype(int)\n",
    "    df['av_physical'] = vec.str.contains('AV:P', na=False).astype(int)\n",
    "\n",
    "    df['ac_low'] = vec.str.contains('AC:L', na=False).astype(int)\n",
    "    df['ac_high'] = vec.str.contains('AC:H', na=False).astype(int)\n",
    "\n",
    "    # ---------- Final numeric feature list ----------\n",
    "    numeric_cols = (\n",
    "        num_cols_raw +\n",
    "        [\n",
    "            'cvss_severity_num',\n",
    "            'age_days',\n",
    "            'published_year',\n",
    "            'published_month',\n",
    "            'av_network',\n",
    "            'av_adjacent',\n",
    "            'av_local',\n",
    "            'av_physical',\n",
    "            'ac_low',\n",
    "            'ac_high',\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_num = df[numeric_cols].fillna(0).values\n",
    "\n",
    "    # ---------- Text features (TF-IDF on description) ----------\n",
    "    desc = (\n",
    "        df['description']\n",
    "        .fillna('')\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.replace(r'[^a-zA-Z0-9 ]', ' ', regex=True)\n",
    "        .str.lower()\n",
    "    )\n",
    "\n",
    "    tfidf = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2\n",
    "    )\n",
    "    X_text = tfidf.fit_transform(desc)\n",
    "\n",
    "    # ---------- Combine numeric + text ----------\n",
    "    X = hstack([X_text, X_num]).tocsr()\n",
    "\n",
    "    return X, y, tfidf, numeric_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45d5d3",
   "metadata": {},
   "source": [
    "### Summary of Feature Engineering\n",
    "\n",
    "The feature engineering function creates three major feature groups\n",
    "#### 1. TEXT FEATURES (TF-IDF on description)\n",
    "* Bag-of-words and bi-grams from **description** are engineered\n",
    "* Text contains the strongest attack intent signal.\n",
    "* Exploited CVEs often include: “RCE”, “zero-click”, “unauthenticated”, “public exploit available”,  “Ivanti / Fortinet / Exchange”.\n",
    "TF-IDF automatically captures this.\n",
    "\n",
    "#### 2. NUMERIC FEATURES (Structured fields from NVD)\n",
    "##### ➤ 2.1 CVSS & scoring metadata  \n",
    "\n",
    "| Feature                | Why it matters                                        |\n",
    "| ---------------------- | ----------------------------------------------------- |\n",
    "| `cvss_score`           | Higher severity often correlates with exploitability. |\n",
    "| `exploitability_score` | Direct predictor of ease-of-exploitation.             |\n",
    "| `impact_score`         | Higher impact = higher attacker motivation.           |\n",
    "| `cvss_severity_num`    | Encoded as NONE=0 → CRITICAL=4.                       |\n",
    "\n",
    "##### ➤ 2.2 Reference-based features  \n",
    "\n",
    "| Feature                            | Meaning                           | Why it matters                                     |\n",
    "| ---------------------------------- | --------------------------------- | -------------------------------------------------- |\n",
    "| `references_count`                 | How many sources mention this CVE | More attention → more likelihood of exploitation   |\n",
    "| `references_exploit_count`         | Exploit links found in references | **VERY strong predictor**                          |\n",
    "| `references_patch_count`           | Patch references                  | Patch availability can correlate with exploitation |\n",
    "| `references_vendor_advisory_count` | Vendor security bulletins         | High-profile vendors = more attacks                |\n",
    "| `has_exploit_tag`                  | Whether NVD auto-tagged exploit   | Direct exploitation signal                         |\n",
    "\n",
    "##### ➤ 2.3 Temporal features  \n",
    "| Feature           | Meaning                                                             |\n",
    "| ----------------- | ------------------------------------------------------------------- |\n",
    "| `age_days`        | Time between publication and last modification                      |\n",
    "| `published_year`  | Captures trends (e.g., huge spike in 2023–2024 enterprise exploits) |\n",
    "| `published_month` | Some months have seasonal attacker activity                         |\n",
    "\n",
    "##### ➤ 2.4 CVSS Vector String features\n",
    "| Feature       | Encodes                        |\n",
    "| ------------- | ------------------------------ |\n",
    "| `av_network`  | Attack Vector = Network (AV:N) |\n",
    "| `av_adjacent` | AV:A                           |\n",
    "| `av_local`    | AV:L                           |\n",
    "| `av_physical` | AV:P                           |\n",
    "| `ac_low`      | Attack Complexity low          |\n",
    "| `ac_high`     | Attack Complexity high         |\n",
    "\n",
    "\n",
    "#### 3. FINAL FEATURE MATRIX = [TF-IDF text features + numeric features]\n",
    "* They are combined using X = hstack([X_text, X_num])  \n",
    "\n",
    "\n",
    "##### Requirements - Analysis of CVSS scores, vulnerability types, affected software categories, temporal characteristics, description text\n",
    "\n",
    "##### 1. CVSS Scores\n",
    "The features include: \n",
    "* cvss_score\n",
    "* impact_score\n",
    "* exploitability_score\n",
    "* cvss_severity_num\n",
    "* cvss_vector (parsed into: av_network, av_local, av_adjacent, av_physical and ac_low, ac_high)\n",
    "\n",
    "\n",
    "##### 2. Vulnerability types\n",
    "Implemented through TF-IDF text features (captures RCE, overflow, auth bypass, traversal, injection…)\n",
    "\n",
    "##### 3. Affected software categories\n",
    "Implemented through \n",
    "* Vendor names implicitly captured in TF-IDF (e.g., Ivanti, Microsoft)\n",
    "* 'affected_products' handled as text features\n",
    "\n",
    "##### 4. Temporal characteristics\n",
    "The features include:\n",
    "* published_year\n",
    "* published_month\n",
    "* age_days\n",
    "\n",
    "##### 5. Description text\n",
    "The feature engineering includes:\n",
    "* Cleaned description text\n",
    "* TF-IDF with 5000 features\n",
    "* Bigram support (captures phrases like “remote code”, “authentication bypass”)\n",
    "\n",
    "##### 6. Handling severe class imbalance\n",
    "The dataset has maybe 10–30 exploited CVEs out of ~2000 → extreme imbalance.\n",
    "The pipeline is ready for:\n",
    "* SMOTE\n",
    "* class_weight=\"balanced\"\n",
    "* XGBoost scale_pos_weight\n",
    "Hence, it fully supports imbalance handling.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff779b",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a204675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_train_test_split(df, test_size=0.3):\n",
    "    \"\"\"\n",
    "    Split data temporally: train on earlier CVEs, test on later CVEs.\n",
    "    This mimics real-world deployment where you predict future exploitation.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values('published').reset_index(drop=True)\n",
    "    split_idx = int(len(df_sorted) * (1 - test_size))\n",
    "    \n",
    "    train_df = df_sorted.iloc[:split_idx]\n",
    "    test_df = df_sorted.iloc[split_idx:]\n",
    "    \n",
    "    print(f\"Temporal split: Train {len(train_df)} CVEs | Test {len(test_df)} CVEs\")\n",
    "    print(f\"Train exploited: {train_df['exploited'].sum()} ({train_df['exploited'].mean():.1%})\")\n",
    "    print(f\"Test exploited: {test_df['exploited'].sum()} ({test_df['exploited'].mean():.1%})\")\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb822119",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test=None, y_test=None):\n",
    "    \"\"\"\n",
    "    Train Logistic Regression with class weighting and calibration for imbalanced data.\n",
    "    \"\"\"\n",
    "    # Compute class weights for imbalance\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "    \n",
    "    print(f\"Class weights: {class_weight_dict}\")\n",
    "    \n",
    "    # Logistic Regression with L2 regularization and class weights\n",
    "    base_model = LogisticRegression(\n",
    "        random_state=SEED,\n",
    "        class_weight=class_weight_dict,\n",
    "        penalty='l2',\n",
    "        C=1.0,\n",
    "        max_iter=1000,\n",
    "        solver='liblinear'\n",
    "    )\n",
    "    \n",
    "    # Calibrate probabilities for better PR-AUC\n",
    "    model = CalibratedClassifierCV(base_model, method='sigmoid', cv=3)\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set if provided\n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(f\"\\nModel trained! Test predictions ready.\")\n",
    "        return model, y_pred, y_pred_proba\n",
    "    \n",
    "    return model, None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bef00",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c04fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation for imbalanced classification.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Primary metrics for imbalanced data\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"ROC-AUC:        {auc_roc:.3f}\")\n",
    "    print(f\"PR-AUC:         {auc_pr:.3f}\")\n",
    "    print(f\"Test Baseline:  {y_test.mean():.3f}\")\n",
    "    \n",
    "    # Precision-Recall curve optimal threshold\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-9)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    print(f\"Optimal PR F1 threshold: {optimal_threshold:.3f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Not Exploited', 'Exploited']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return {\n",
    "        'roc_auc': auc_roc,\n",
    "        'pr_auc': auc_pr,\n",
    "        'optimal_threshold': optimal_threshold,\n",
    "        'confusion_matrix': cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06e71b",
   "metadata": {},
   "source": [
    "## Show top Features for Intrepretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e57040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_features(model, tfidf, numeric_cols, top_k=20):\n",
    "    \"\"\"\n",
    "    Display top important features for interpretability.\n",
    "    Works with:\n",
    "      - plain linear models (with .coef_)\n",
    "      - CalibratedClassifierCV wrapping a linear model\n",
    "    \"\"\"\n",
    "    # Get feature names (TF-IDF + numeric)\n",
    "    feature_names = list(tfidf.get_feature_names_out()) + numeric_cols\n",
    "\n",
    "    # --- Extract coefficients depending on model type ---\n",
    "    if hasattr(model, \"coef_\"):\n",
    "        # e.g. plain LogisticRegression\n",
    "        coefs = model.coef_[0]\n",
    "\n",
    "    elif hasattr(model, \"calibrated_classifiers_\"):\n",
    "        # CalibratedClassifierCV: grab the underlying estimator from first fold\n",
    "        calib = model.calibrated_classifiers_[0]\n",
    "\n",
    "        base_est = None\n",
    "        if hasattr(calib, \"base_estimator\"):\n",
    "            base_est = calib.base_estimator\n",
    "        elif hasattr(calib, \"estimator\"):\n",
    "            base_est = calib.estimator\n",
    "\n",
    "        if base_est is None or not hasattr(base_est, \"coef_\"):\n",
    "            raise ValueError(\n",
    "                \"Underlying calibrated estimator does not expose coef_. \"\n",
    "                \"Make sure you are using a linear model like LogisticRegression.\"\n",
    "            )\n",
    "\n",
    "        coefs = base_est.coef_[0]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Model type not supported for feature inspection. \"\n",
    "            \"Expected a linear model or CalibratedClassifierCV wrapping one.\"\n",
    "        )\n",
    "\n",
    "    # --- Top positive features (indicating higher exploitation risk) ---\n",
    "    top_indices = np.argsort(coefs)[-top_k:]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TOP FEATURES FOR EXPLOITATION PREDICTION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nTop keywords/phrases / numeric features indicating exploitation:\")\n",
    "\n",
    "    for rank, idx in enumerate(top_indices, start=1):\n",
    "        fname = feature_names[idx] if idx < len(feature_names) else f\"feature_{idx}\"\n",
    "        print(f\"{rank:2d}. {fname:40s} (coef: {coefs[idx]:8.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4682e42",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af82ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, tfidf, numeric_cols, filepath_prefix=\"cve_exploitation_model\"):\n",
    "    \"\"\"\n",
    "    Save trained model and preprocessing pipeline.\n",
    "    \"\"\"\n",
    "    joblib.dump(model, f\"{filepath_prefix}_model.pkl\")\n",
    "    joblib.dump(tfidf, f\"{filepath_prefix}_tfidf.pkl\")\n",
    "    joblib.dump(numeric_cols, f\"{filepath_prefix}_numeric_cols.pkl\")\n",
    "    \n",
    "    print(f\"\\nModel saved as:\")\n",
    "    print(f\"- {filepath_prefix}_model.pkl\")\n",
    "    print(f\"- {filepath_prefix}_tfidf.pkl\") \n",
    "    print(f\"- {filepath_prefix}_numeric_cols.pkl\")\n",
    "    \n",
    "    return f\"{filepath_prefix}_model.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134f3d9",
   "metadata": {},
   "source": [
    "## Predict New CVE'S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_cves(model, tfidf, numeric_cols, new_cves_df):\n",
    "    \"\"\"\n",
    "    Predict exploitation probability for new CVEs.\n",
    "\n",
    "    Uses the same feature engineering as `engineer_features`, but:\n",
    "      - reuses the fitted `tfidf` vectorizer\n",
    "      - uses the passed `numeric_cols` list to align feature order\n",
    "    \"\"\"\n",
    "    df = new_cves_df.copy()\n",
    "\n",
    "    # --- Temporal features (same as engineer_features) ---\n",
    "    df['published'] = pd.to_datetime(df['published'], errors='coerce')\n",
    "    df['last_modified'] = pd.to_datetime(df['last_modified'], errors='coerce')\n",
    "\n",
    "    df['age_days'] = (df['last_modified'] - df['published']).dt.days\n",
    "    df['age_days'] = df['age_days'].fillna(0).clip(lower=0)\n",
    "\n",
    "    df['published_year'] = df['published'].dt.year\n",
    "    df['published_month'] = df['published'].dt.month\n",
    "\n",
    "    # --- CVSS severity numeric (same mapping) ---\n",
    "    severity_map = {\n",
    "        'NONE': 0,\n",
    "        'LOW': 1,\n",
    "        'MEDIUM': 2,\n",
    "        'HIGH': 3,\n",
    "        'CRITICAL': 4\n",
    "    }\n",
    "    df['cvss_severity_num'] = df['cvss_severity'].map(severity_map).fillna(0).astype(int)\n",
    "\n",
    "    # --- CVSS vector flags (same as engineer_features) ---\n",
    "    vec = df['cvss_vector'].fillna('')\n",
    "\n",
    "    df['av_network'] = vec.str.contains('AV:N', na=False).astype(int)\n",
    "    df['av_adjacent'] = vec.str.contains('AV:A', na=False).astype(int)\n",
    "    df['av_local'] = vec.str.contains('AV:L', na=False).astype(int)\n",
    "    df['av_physical'] = vec.str.contains('AV:P', na=False).astype(int)\n",
    "\n",
    "    df['ac_low'] = vec.str.contains('AC:L', na=False).astype(int)\n",
    "    df['ac_high'] = vec.str.contains('AC:H', na=False).astype(int)\n",
    "\n",
    "    # --- Ensure all numeric_cols exist and are numeric ---\n",
    "    for col in numeric_cols:\n",
    "        if col not in df.columns:\n",
    "            # For any missing numeric column, just fill with 0\n",
    "            df[col] = 0\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    X_num = df[numeric_cols].values\n",
    "\n",
    "    # --- Text features: use the *same cleaning* and transform with fitted tfidf ---\n",
    "    desc = (\n",
    "        df['description']\n",
    "        .fillna('')\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.replace(r'[^a-zA-Z0-9 ]', ' ', regex=True)\n",
    "        .str.lower()\n",
    "    )\n",
    "    X_text = tfidf.transform(desc)\n",
    "\n",
    "    # --- Combine text + numeric in same order/shape as training ---\n",
    "    X_new = hstack([X_text, X_num]).tocsr()\n",
    "\n",
    "    # --- Predict ---\n",
    "    proba = model.predict_proba(X_new)[:, 1]\n",
    "    predictions = model.predict(X_new)\n",
    "\n",
    "    results = df[['cve_id', 'cvss_score', 'cvss_severity', 'description']].copy()\n",
    "    results['exploitation_probability'] = proba\n",
    "    results['predicted_exploited'] = predictions\n",
    "    results['risk_score'] = pd.cut(\n",
    "        proba,\n",
    "        bins=[0, 0.1, 0.3, 0.7, 1.0],\n",
    "        labels=['Low', 'Medium', 'High', 'Critical'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    return results.sort_values('exploitation_probability', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f2ea6",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f87fa-a666-42e2-95f9-6669feb5e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CISA KEV data...\n",
      "Loaded 1467 exploited CVEs from CISA. Sample....\n",
      "                                             title catalogVersion  \\\n",
      "0  CISA Catalog of Known Exploited Vulnerabilities     2025.12.03   \n",
      "1  CISA Catalog of Known Exploited Vulnerabilities     2025.12.03   \n",
      "2  CISA Catalog of Known Exploited Vulnerabilities     2025.12.03   \n",
      "3  CISA Catalog of Known Exploited Vulnerabilities     2025.12.03   \n",
      "4  CISA Catalog of Known Exploited Vulnerabilities     2025.12.03   \n",
      "\n",
      "                dateReleased  count  \\\n",
      "0  2025-12-03T18:00:03.1141Z   1467   \n",
      "1  2025-12-03T18:00:03.1141Z   1467   \n",
      "2  2025-12-03T18:00:03.1141Z   1467   \n",
      "3  2025-12-03T18:00:03.1141Z   1467   \n",
      "4  2025-12-03T18:00:03.1141Z   1467   \n",
      "\n",
      "                                     vulnerabilities  \n",
      "0  {'cveID': 'CVE-2021-26828', 'vendorProject': '...  \n",
      "1  {'cveID': 'CVE-2025-48633', 'vendorProject': '...  \n",
      "2  {'cveID': 'CVE-2025-48572', 'vendorProject': '...  \n",
      "3  {'cveID': 'CVE-2021-26829', 'vendorProject': '...  \n",
      "4  {'cveID': 'CVE-2025-61757', 'vendorProject': '...  \n",
      "\n",
      " Fetching CVEs for given date range...\n",
      "Loaded 8153 CVEs from NVD. Sample....\n",
      "                                                 cve\n",
      "0  {'id': 'CVE-2024-21675', 'sourceIdentifier': '...\n",
      "1  {'id': 'CVE-2024-21679', 'sourceIdentifier': '...\n",
      "2  {'id': 'CVE-2024-21688', 'sourceIdentifier': '...\n",
      "3  {'id': 'CVE-2024-21691', 'sourceIdentifier': '...\n",
      "4  {'id': 'CVE-2024-21692', 'sourceIdentifier': '...\n",
      "\n",
      " Flatten CVEs...\n",
      "           cve_id               published           last_modified vuln_status  \\\n",
      "0  CVE-2024-21675 2025-01-01 00:15:07.193 2025-01-01 00:15:07.193    Rejected   \n",
      "1  CVE-2024-21679 2025-01-01 00:15:07.267 2025-01-01 00:15:07.267    Rejected   \n",
      "2  CVE-2024-21688 2025-01-01 00:15:36.373 2025-01-01 00:15:36.373    Rejected   \n",
      "3  CVE-2024-21691 2025-01-01 00:15:36.447 2025-01-01 00:15:36.447    Rejected   \n",
      "4  CVE-2024-21692 2025-01-01 00:15:36.510 2025-01-01 00:15:36.510    Rejected   \n",
      "\n",
      "  cvss_version cvss_score cvss_severity cvss_vector exploitability_score  \\\n",
      "0         None       None          None        None                 None   \n",
      "1         None       None          None        None                 None   \n",
      "2         None       None          None        None                 None   \n",
      "3         None       None          None        None                 None   \n",
      "4         None       None          None        None                 None   \n",
      "\n",
      "  impact_score  ... affected_part_categories affected_vendors  \\\n",
      "0         None  ...                     None             None   \n",
      "1         None  ...                     None             None   \n",
      "2         None  ...                     None             None   \n",
      "3         None  ...                     None             None   \n",
      "4         None  ...                     None             None   \n",
      "\n",
      "  affected_products affected_versions references_count  \\\n",
      "0              None              None                0   \n",
      "1              None              None                0   \n",
      "2              None              None                0   \n",
      "3              None              None                0   \n",
      "4              None              None                0   \n",
      "\n",
      "   references_exploit_count  references_patch_count  \\\n",
      "0                         0                       0   \n",
      "1                         0                       0   \n",
      "2                         0                       0   \n",
      "3                         0                       0   \n",
      "4                         0                       0   \n",
      "\n",
      "   references_vendor_advisory_count  has_exploit_tag  \\\n",
      "0                                 0                0   \n",
      "1                                 0                0   \n",
      "2                                 0                0   \n",
      "3                                 0                0   \n",
      "4                                 0                0   \n",
      "\n",
      "                                         description  \n",
      "0  Rejected reason: To maintain compliance with C...  \n",
      "1  Rejected reason: To maintain compliance with C...  \n",
      "2  Rejected reason: To maintain compliance with C...  \n",
      "3  Rejected reason: To maintain compliance with C...  \n",
      "4  Rejected reason: To maintain compliance with C...  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Labeling exploited vulnerabilities...\n",
      "\n",
      "Class Distribution:\n",
      "0    8124\n",
      "1      29\n",
      "Name: exploited, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== CLEANING DATA ==========\n",
      "Original shape: (8153, 22)\n",
      "\n",
      "Original vuln_status counts:\n",
      "Analyzed               3958\n",
      "Awaiting Analysis      2866\n",
      "Modified               1030\n",
      "Rejected                294\n",
      "Undergoing Analysis       5\n",
      "Name: vuln_status, dtype: int64\n",
      "\n",
      "Original exploited label counts:\n",
      "0    8124\n",
      "1      29\n",
      "Name: exploited, dtype: int64\n",
      "\n",
      "Cleaned shape: (4993, 22)\n",
      "\n",
      "Cleaned vuln_status counts:\n",
      "Analyzed               3958\n",
      "Modified               1030\n",
      "Undergoing Analysis       5\n",
      "Name: vuln_status, dtype: int64\n",
      "\n",
      "Cleaned exploited label counts:\n",
      "0    4964\n",
      "1      29\n",
      "Name: exploited, dtype: int64\n",
      "\n",
      "Head of cleaned dataframe:\n",
      "           cve_id               published           last_modified vuln_status  \\\n",
      "0  CVE-2024-47475 2025-01-06 17:15:37.423 2025-01-09 16:04:01.680    Analyzed   \n",
      "1  CVE-2024-56761 2025-01-06 17:15:41.480 2025-01-09 16:16:23.667    Modified   \n",
      "2  CVE-2024-43063 2025-01-06 11:15:08.930 2025-01-10 15:37:33.340    Analyzed   \n",
      "3  CVE-2024-33061 2025-01-06 11:15:08.617 2025-01-10 16:49:42.207    Analyzed   \n",
      "4  CVE-2024-33059 2025-01-06 11:15:08.470 2025-01-10 16:53:02.590    Analyzed   \n",
      "\n",
      "  cvss_version cvss_score cvss_severity cvss_vector exploitability_score  \\\n",
      "0         None       None          None        None                 None   \n",
      "1         None       None          None        None                 None   \n",
      "2         None       None          None        None                 None   \n",
      "3         None       None          None        None                 None   \n",
      "4         None       None          None        None                 None   \n",
      "\n",
      "  impact_score  ... affected_vendors affected_products affected_versions  \\\n",
      "0         None  ...             None              None              None   \n",
      "1         None  ...             None              None              None   \n",
      "2         None  ...             None              None              None   \n",
      "3         None  ...             None              None              None   \n",
      "4         None  ...             None              None              None   \n",
      "\n",
      "  references_count references_exploit_count  references_patch_count  \\\n",
      "0                1                        0                       0   \n",
      "1                3                        0                       2   \n",
      "2                1                        0                       0   \n",
      "3                1                        0                       1   \n",
      "4                1                        0                       1   \n",
      "\n",
      "   references_vendor_advisory_count  has_exploit_tag  \\\n",
      "0                                 1                0   \n",
      "1                                 0                0   \n",
      "2                                 1                0   \n",
      "3                                 1                0   \n",
      "4                                 1                0   \n",
      "\n",
      "                                         description  exploited  \n",
      "0  Dell PowerScale OneFS 8.2.2.x through 9.8.0.x ...          0  \n",
      "1  In the Linux kernel, the following vulnerabili...          0  \n",
      "2  information disclosure while invoking the mail...          0  \n",
      "3  Information disclosure while processing IOCTL ...          0  \n",
      "4  Memory corruption while processing frame comma...          0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "========== FEATURE ENGINEERING ==========\n",
      "\n",
      "Feature matrix shape (X): (4993, 5018)\n",
      "Number of labels (y): 4993\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # 1. Data Colletion\n",
    "    kev_ids, kev_df = load_cisa_kev()\n",
    "\n",
    "    # The maximum allowable range when using any date range parameters is 120 consecutive days. Also, max result per page is 2000\n",
    "    cve_df = fetch_cves(\"2025-01-01\",\"2025-02-28\",2000,\"a264b5f4-4416-4670-ab78-00258dcb0e72\")\n",
    "\n",
    "    # 2. Processing\n",
    "    flatten_cve_df = flatten_cve(cve_df)\n",
    "    \n",
    "    # 3. Label the data\n",
    "    labelled_cve_df = label_cve_data(flatten_cve_df, kev_ids)\n",
    "    \n",
    "    # 4. Cleaning\n",
    "    # Before cleaning\n",
    "    print(\"\\n========== CLEANING DATA ==========\")\n",
    "    print(\"Original shape:\", labelled_cve_df.shape)\n",
    "    print(\"\\nOriginal vuln_status counts:\")\n",
    "    print(labelled_cve_df['vuln_status'].value_counts())\n",
    "    print(\"\\nOriginal exploited label counts:\")\n",
    "    print(labelled_cve_df['exploited'].value_counts())\n",
    "\n",
    "    # Clean the whole dataset (~2000 records)\n",
    "    clean_df = clean_cve_dataset(labelled_cve_df)\n",
    "\n",
    "    # After cleaning\n",
    "    print(\"\\nCleaned shape:\", clean_df.shape)\n",
    "    print(\"\\nCleaned vuln_status counts:\")\n",
    "    print(clean_df['vuln_status'].value_counts())\n",
    "    print(\"\\nCleaned exploited label counts:\")\n",
    "    print(clean_df['exploited'].value_counts())\n",
    "\n",
    "    # Quick peek\n",
    "    print(\"\\nHead of cleaned dataframe:\")\n",
    "    print(clean_df.head())\n",
    "\n",
    "    # 5. Feature Engineering\n",
    "    print(\"\\n========== FEATURE ENGINEERING ==========\")\n",
    "    X, y, tfidf, numeric_cols = engineer_features(clean_df)\n",
    "\n",
    "    print(\"\\nFeature matrix shape (X):\", X.shape)   # (n_samples, n_features)\n",
    "    print(\"Number of labels (y):\", len(y))        # n_samples\n",
    "\n",
    "    # 6. Temporal train/test split\n",
    "    train_df, test_df = temporal_train_test_split(clean_df)\n",
    "\n",
    "     # 7. Prepare train/test features (subset from full feature matrix)\n",
    "    train_idx = clean_df[clean_df['cve_id'].isin(train_df['cve_id'])].index\n",
    "    test_idx = clean_df[clean_df['cve_id'].isin(test_df['cve_id'])].index\n",
    "\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    # 8. Train model\n",
    "    model, y_pred, y_pred_proba = train_model(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # 9. Evaluate\n",
    "    metrics = evaluate_model(model, X_test, y_test, y_pred_proba)\n",
    "\n",
    "    # 10. Feature importance\n",
    "    show_top_features(model, tfidf, numeric_cols)\n",
    "\n",
    "    # 11. Save model\n",
    "    model_path = save_model(model, tfidf, numeric_cols)\n",
    "\n",
    "    # 12. High-risk predictions\n",
    "    results = predict_new_cves(model, tfidf, numeric_cols, test_df)\n",
    "    print(\"\\nTop 10 Highest Risk CVEs (Test Set):\")\n",
    "    print(results.head(10)[['cve_id', 'exploitation_probability', 'risk_score']].to_csv(index=False))\n",
    "\n",
    "    \n",
    "    # Return everything you’ll likely need later\n",
    "    return clean_df, X, y, tfidf, numeric_cols, labelled_cve_df, model, metrics, results, model_path\n",
    "\n",
    "    #X, y, tfidf = generate_features(df)\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = temporal_split(df, X, y)\n",
    "\n",
    "   # X_train, y_train = balance_data(X_train, y_train)\n",
    "\n",
    "    #model = train_model(X_train, y_train)\n",
    "\n",
    "    #evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    #show_top_features(model, tfidf)\n",
    "\n",
    "    #save_files(model, tfidf)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    clean_df, X, y, tfidf, numeric_cols, labelled_cve_df, model, metrics, results, model_path  = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76c18c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cve_id</th>\n",
       "      <th>published</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>vuln_status</th>\n",
       "      <th>cvss_version</th>\n",
       "      <th>cvss_score</th>\n",
       "      <th>cvss_severity</th>\n",
       "      <th>cvss_vector</th>\n",
       "      <th>exploitability_score</th>\n",
       "      <th>impact_score</th>\n",
       "      <th>...</th>\n",
       "      <th>affected_vendors</th>\n",
       "      <th>affected_products</th>\n",
       "      <th>affected_versions</th>\n",
       "      <th>references_count</th>\n",
       "      <th>references_exploit_count</th>\n",
       "      <th>references_patch_count</th>\n",
       "      <th>references_vendor_advisory_count</th>\n",
       "      <th>has_exploit_tag</th>\n",
       "      <th>description</th>\n",
       "      <th>exploited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVE-2024-47475</td>\n",
       "      <td>2025-01-06 17:15:37.423</td>\n",
       "      <td>2025-01-09 16:04:01.680</td>\n",
       "      <td>Analyzed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Dell PowerScale OneFS 8.2.2.x through 9.8.0.x ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVE-2024-56761</td>\n",
       "      <td>2025-01-06 17:15:41.480</td>\n",
       "      <td>2025-01-09 16:16:23.667</td>\n",
       "      <td>Modified</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>In the Linux kernel, the following vulnerabili...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVE-2024-43063</td>\n",
       "      <td>2025-01-06 11:15:08.930</td>\n",
       "      <td>2025-01-10 15:37:33.340</td>\n",
       "      <td>Analyzed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>information disclosure while invoking the mail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CVE-2024-33061</td>\n",
       "      <td>2025-01-06 11:15:08.617</td>\n",
       "      <td>2025-01-10 16:49:42.207</td>\n",
       "      <td>Analyzed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Information disclosure while processing IOCTL ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVE-2024-33059</td>\n",
       "      <td>2025-01-06 11:15:08.470</td>\n",
       "      <td>2025-01-10 16:53:02.590</td>\n",
       "      <td>Analyzed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Memory corruption while processing frame comma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cve_id               published           last_modified vuln_status  \\\n",
       "0  CVE-2024-47475 2025-01-06 17:15:37.423 2025-01-09 16:04:01.680    Analyzed   \n",
       "1  CVE-2024-56761 2025-01-06 17:15:41.480 2025-01-09 16:16:23.667    Modified   \n",
       "2  CVE-2024-43063 2025-01-06 11:15:08.930 2025-01-10 15:37:33.340    Analyzed   \n",
       "3  CVE-2024-33061 2025-01-06 11:15:08.617 2025-01-10 16:49:42.207    Analyzed   \n",
       "4  CVE-2024-33059 2025-01-06 11:15:08.470 2025-01-10 16:53:02.590    Analyzed   \n",
       "\n",
       "  cvss_version cvss_score cvss_severity cvss_vector exploitability_score  \\\n",
       "0         None       None          None        None                 None   \n",
       "1         None       None          None        None                 None   \n",
       "2         None       None          None        None                 None   \n",
       "3         None       None          None        None                 None   \n",
       "4         None       None          None        None                 None   \n",
       "\n",
       "  impact_score  ... affected_vendors affected_products affected_versions  \\\n",
       "0         None  ...             None              None              None   \n",
       "1         None  ...             None              None              None   \n",
       "2         None  ...             None              None              None   \n",
       "3         None  ...             None              None              None   \n",
       "4         None  ...             None              None              None   \n",
       "\n",
       "  references_count references_exploit_count  references_patch_count  \\\n",
       "0                1                        0                       0   \n",
       "1                3                        0                       2   \n",
       "2                1                        0                       0   \n",
       "3                1                        0                       1   \n",
       "4                1                        0                       1   \n",
       "\n",
       "   references_vendor_advisory_count  has_exploit_tag  \\\n",
       "0                                 1                0   \n",
       "1                                 0                0   \n",
       "2                                 1                0   \n",
       "3                                 1                0   \n",
       "4                                 1                0   \n",
       "\n",
       "                                         description  exploited  \n",
       "0  Dell PowerScale OneFS 8.2.2.x through 9.8.0.x ...          0  \n",
       "1  In the Linux kernel, the following vulnerabili...          0  \n",
       "2  information disclosure while invoking the mail...          0  \n",
       "3  Information disclosure while processing IOCTL ...          0  \n",
       "4  Memory corruption while processing frame comma...          0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b306f",
   "metadata": {},
   "source": [
    "## TRAIN/TEST\n",
    "\n",
    "###### Please remove this line. It is for the next person's reference - Use 'clean_df' to proceed for further analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
